{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "X, y = load_iris(return_X_y=True)\n",
    "clf = LogisticRegressionCV(cv=5, random_state=0,\n",
    "                           multi_class='multinomial').fit(X, y)\n",
    "clf.predict(X[:2, :])\n",
    "\n",
    "clf.predict_proba(X[:2, :]).shape\n",
    "\n",
    "clf.score(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=Ridge(),\n",
      "             param_grid={'alpha': array([1.0e+00, 1.0e-01, 1.0e-02, 1.0e-03, 1.0e-04, 0.0e+00, 5.0e-03,\n",
      "       6.0e-03, 4.5e-02])})\n",
      "0.4823231384163484\n",
      "0.0001\n"
     ]
    }
   ],
   "source": [
    "# Grid Search for Algorithm Tuning\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "# prepare a range of alpha values to test\n",
    "alphas = np.array([1,0.1,0.01,0.001,0.0001,0,0.005,0.006,0.045])\n",
    "# create and fit a ridge regression model, testing each alpha\n",
    "model = Ridge()\n",
    "grid = GridSearchCV(estimator=model, param_grid=dict(alpha=alphas))\n",
    "grid.fit(dataset.data, dataset.target)\n",
    "print(grid)\n",
    "# summarize the results of the grid search\n",
    "print(grid.best_score_)\n",
    "\n",
    "print(grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=SVC(),\n",
      "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})\n",
      "Best Score: 0.9800000000000001\n",
      "Best Estimator: SVC(C=1, kernel='linear')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "print(clf)\n",
    "# summarize the results of the grid search\n",
    "print('Best Score:',clf.best_score_)\n",
    "\n",
    "print('Best Estimator:',clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(estimator=SVC(),\n",
      "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
      "                         'gamma': [1, 0.1, 0.001, 0.0001, 1e-05, 1e-06],\n",
      "                         'kernel': ('linear', 'poly', 'rbf', 'sigmoid')})\n",
      "Best Score: 0.9866666666666667\n",
      "Best Estimator: SVC(C=1000, gamma=0.001, kernel='sigmoid')\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'C':[0.1,1, 10,100,1000],'gamma':[1,0.1,0.001,0.0001,0.00001,0.000001]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(iris.data, iris.target)\n",
    "print(clf)\n",
    "# summarize the results of the grid search\n",
    "print('Best Score:',clf.best_score_)\n",
    "\n",
    "print('Best Estimator:',clf.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Randomized Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(estimator=Ridge(),\n",
      "                   param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x0000025FC4023460>})\n",
      "0.48068193427300565\n",
      "0.06267326831206854\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search for Algorithm Tuning\n",
    "import numpy as np\n",
    "from scipy.stats import uniform \n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': uniform()}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10)\n",
    "rsearch.fit(dataset.data, dataset.target)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(cv=None, error_score='raise',\n",
      "          estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
      "   normalize=False, random_state=None, solver='auto', tol=0.001),\n",
      "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
      "          param_distributions={'alpha': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000000D3A8FC1240>},\n",
      "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n",
      "0.4891095321395234\n",
      "0.04545764086321924\n"
     ]
    }
   ],
   "source": [
    "# Randomized Search for Algorithm Tuning\n",
    "import numpy as np\n",
    "from scipy.stats import uniform as sp_rand\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# load the diabetes datasets\n",
    "dataset = datasets.load_diabetes()\n",
    "# prepare a uniform distribution to sample for the alpha parameter\n",
    "param_grid = {'alpha': sp_rand()}\n",
    "# create and fit a ridge regression model, testing random alpha values\n",
    "model = Ridge()\n",
    "rsearch = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=10)\n",
    "rsearch.fit(dataset.data, dataset.target)\n",
    "print(rsearch)\n",
    "# summarize the results of the random parameter search\n",
    "print(rsearch.best_score_)\n",
    "print(rsearch.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomized Search Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV(estimator=LogisticRegression(max_iter=200, random_state=0,\n",
      "                                                solver='saga', tol=0.01),\n",
      "                   n_iter=15,\n",
      "                   param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000001BE0F36C160>,\n",
      "                                        'penalty': ['l2', 'l1']},\n",
      "                   random_state=0)\n",
      "Best Score: 0.9800000000000001\n",
      "Best Estimator: LogisticRegression(C=2.195254015709299, max_iter=200, penalty='l1',\n",
      "                   random_state=0, solver='saga', tol=0.01)\n",
      "{'C': 2.195254015709299, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    ">>> from sklearn.linear_model import LogisticRegression\n",
    ">>> from sklearn.model_selection import RandomizedSearchCV\n",
    ">>> from scipy.stats import uniform\n",
    ">>> iris = load_iris()\n",
    ">>> logistic = LogisticRegression(solver='saga', tol=1e-2, max_iter=200,\n",
    "...                               random_state=0)\n",
    ">>> distributions = dict(C=uniform(loc=0, scale=4),\n",
    "...                      penalty=['l2', 'l1'])\n",
    ">>> clf = RandomizedSearchCV(logistic, distributions, random_state=0,n_iter=15)\n",
    ">>> clf.fit(iris.data, iris.target)\n",
    "print(clf)\n",
    "# summarize the results of the grid search\n",
    "print('Best Score:',clf.best_score_)\n",
    "\n",
    "print('Best Estimator:',clf.best_estimator_)\n",
    ">>> print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/justmarkham/scikit-learn-videos/blob/master/08_grid_search.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/codebasics/py/blob/master/ML/15_gridsearch/15_grid_search.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### https://github.com/codebasics/py/blob/master/ML/15_gridsearch/Exercise/15_grid_search_cv_exercise.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.07929254 0.85576344 0.03174793 0.03319609]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "X, y = make_classification(n_samples=1000, n_features=4,\n",
    "                           n_informative=2, n_redundant=0,\n",
    "                           random_state=0, shuffle=False)\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=8,\n",
    "                             random_state=0)\n",
    "clf.fit(X, y)\n",
    "\n",
    "print(clf.feature_importances_)\n",
    "\n",
    "print(clf.predict([[0, 0, 0, 0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.datasets.samples_generator.make_classification(n_samples=100, n_features=20, n_informative=2, n_redundant=2, n_repeated=0, n_classes=2, n_clusters_per_class=2, weights=None, flip_y=0.01, class_sep=1.0, hypercube=True, shift=0.0, scale=1.0, shuffle=True, random_state=None)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "make_classification"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
